# ğŸ›ï¸ CQRS Architecture â€” Shopping Item Service  
**Tech Stack:** Node.js Â· NestJS Â· PostgreSQL Â· RabbitMQ Â· MongoDB Â· Docker  

This project demonstrates a **microservices-based CQRS (Command Query Responsibility Segregation)** architecture that cleanly separates **command (write)** and **query (read)** responsibilities for a **Shopping Item domain**, ensuring **scalability**, **reliability**, and **real-time data synchronization** through **RabbitMQ** and the **Outbox pattern**.

Itâ€™s designed as a practical example of implementing **event-driven microservices** with clear separation of concerns and **eventual consistency** between data stores.  
The system is fully containerized with **Docker Compose** and can be extended for **Kubernetes deployment** or **CI/CD pipelines**.


---

## ğŸ§± Architecture Overview

![CQRS Architecture Diagram](./docs/CQRS_ShoppingItem.png)

## âš™ï¸ Tech Stack

| Layer | Technology |
|-------|-------------|
| **API Gateway** | NestJS (HTTP Proxy for microservice routing) |
| **Command Service** | Express + TS + PostgreSQL (TypeORM / Sequelize) |
| **Query Service** | Express + TS + MongoDB (Mongoose / ODM) |
| **Messaging** | RabbitMQ (Event-driven communication) |
| **Containerization** | Docker Compose |
| **Language** | TypeScript |

---

## ğŸ—‚ Folder Structure

```bash
shopping-item-service/
â”‚
â”œâ”€â”€ api-gateway/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ controllers/
â”‚       â”‚   â”œâ”€â”€ command.controller.ts
â”‚       â”‚   â””â”€â”€ query.controller.ts
â”‚       â”œâ”€â”€ routes/
â”‚       â”‚   â”œâ”€â”€ items.command.routes.ts
â”‚       â”‚   â””â”€â”€ items.query.routes.ts
â”‚       â”œâ”€â”€ main.ts
â”‚       â””â”€â”€ app.module.ts
â”‚
â”œâ”€â”€ command-service/
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ events/
â”‚       â”‚   â”œâ”€â”€ publisher.ts
â”‚       â”‚   â””â”€â”€ rabbitmq.ts
â”‚       â”œâ”€â”€ handlers/
â”‚       â”‚   â”œâ”€â”€ create-item.handler.ts
â”‚       â”‚   â”œâ”€â”€ update-item.handler.ts
â”‚       â”‚   â””â”€â”€ delete-item.handler.ts
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ item.entity.ts
â”‚       â”‚   â””â”€â”€ outbox.entity.ts
â”‚       â”œâ”€â”€ repositories/
â”‚       â”‚   â”œâ”€â”€ item.repository.ts
â”‚       â”‚   â””â”€â”€ outbox.repository.ts
â”‚       â”œâ”€â”€ workers/
â”‚       â”‚   â””â”€â”€ processOutbox.ts
â”‚       â”œâ”€â”€ utils/
â”‚       â”‚   â””â”€â”€ data-source.ts
â”‚       â””â”€â”€ main.ts
â”‚
â”œâ”€â”€ query-service/
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ events/
â”‚       â”‚   â””â”€â”€ rabbitmq.listener.ts
â”‚       â”œâ”€â”€ handlers/
â”‚       â”‚   â”œâ”€â”€ item-event.handler.ts
â”‚       â”‚   â””â”€â”€ item-update.handler.ts
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â””â”€â”€ item.model.ts
â”‚       â”œâ”€â”€ routes/
â”‚       â”‚   â””â”€â”€ item.routes.ts
â”‚       â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CQRS_ShoppingItem.drawio
â”‚   â””â”€â”€ CQRS_ShoppingItem.png
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

```


## ğŸ”§ Environment Variables
```bash
### ğŸ§© Command Service (`.env`)
PORT=4001
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=user
POSTGRES_PASSWORD=pass
POSTGRES_DB=commanddb
RABBITMQ_URL=amqp://rabbitmq:5672


### ğŸ” Query Service (`.env`)
PORT=4002
MONGO_URI=mongodb://mongodb:27017/querydb
RABBITMQ_URL=amqp://rabbitmq:5672
```

---

## âš™ï¸ Development Workflow (Recommended)
ğŸ“ **Note:** Please run all commands from the root directory â€” `shopping-item-service/`
> ğŸ’¡ **Preferred Local Setup**
>
> For development, itâ€™s recommended to run the **Node.js services** â€”  
> `command-service`, `api-gateway`, and `query-service` â€” **outside of Docker** for:
> - Faster reloads
> - Easier debugging
> - No rebuild overhead
>
> Meanwhile, run the **infrastructure services** â€”  
> ğŸ˜ **PostgreSQL**, ğŸ‡ **RabbitMQ**, and ğŸƒ **MongoDB** â€” **inside Docker** for consistency and isolation.
>
> This hybrid setup provides the best developer experience.  

---

> âš ï¸ **Important:**  
> Donâ€™t forget to run the **Outbox Worker** to publish unprocessed events:
>
> ```bash
> cd command-service
> npm run worker
> ```
>
> Without it, events from the Outbox table wonâ€™t be sent to RabbitMQ, and the **Query Service (MongoDB)** will not receive updates.

---

## ğŸš€ Setup & Run

1ï¸âƒ£ Install Dependencies
```bash
cd api-gateway && npm install
cd command-service && npm install
cd query-service && npm install
 
``` 

2ï¸âƒ£ Run Infrastructure Containers Only

Use Docker Compose to start only the infrastructure stack:
```bash
docker compose up postgres mongo rabbitmq
```

This launches:

ğŸ˜ PostgreSQL â€” for the Command Service (Write side)

ğŸƒ MongoDB â€” for the Query Service (Read side)

ğŸ‡ RabbitMQ â€” for event propagation between services

These containers will stay running in the background and can be reused across multiple development sessions.

3ï¸âƒ£ Run Node Services Locally (Outside Docker)

Open three separate terminals for live reload and debugging:
```bash 
#ğŸ— API Gateway
cd api-gateway
npm run start:dev
```
```bash
# ğŸ§© Command Service
cd command-service
npm run start:dev
```
```bash
# ğŸ“š Query Service
cd query-service
npm run start:dev
```
âœ… Each service connects automatically to its respective database or message broker (running in Docker).

âœ… Instant hot-reload support when using ts-node-dev or nodemon.


4ï¸âƒ£ Run the Outbox Worker

In a separate terminal:
```bash cd command-service
npm run worker
```
This continuously monitors the Outbox table and publishes pending domain events to RabbitMQ, which are then consumed by the Query Service.

### ğŸ§¾ TL;DR
| Environment                | Recommendation                                         |
| -------------------------- | ------------------------------------------------------ |
| ğŸ§ª **Development**         | Run Node services locally + infra in Docker            |
| ğŸ³ **Full Container Mode** | Run all services via `docker compose up`               |
| â˜¸ï¸ **Production**          | Deploy with Kubernetes or ECS and external managed DBs |


ğŸŒ Access Services
| Service                 | URL                                              | Description                          |
| ----------------------- | ------------------------------------------------ | ------------------------------------ |
| **API Gateway**         | [http://localhost:4000](http://localhost:4000)   | Routes to command/query services     |
| **Command Service**     | [http://localhost:4001](http://localhost:4001)   | Handles writes (PostgreSQL)          |
| **Query Service**       | [http://localhost:4002](http://localhost:4002)   | Handles reads (MongoDB)              |
| **RabbitMQ Management** | [http://localhost:15672](http://localhost:15672) | Default user/pass: `guest` / `guest` |

---

---

## ğŸ§ª API Testing with Postman

A ready-to-use **Postman Collection** is included to test all endpoints across the API Gateway, Command Service, and Query Service.

ğŸ“‚ **File:** [`docs/ShoppingItemService.postman_collection.json`](./docs/ShoppingItemService.postman_collection.json)

### ğŸš€ How to Import
1. Open **Postman**
2. Click **File â†’ Import**
3. Select the file:  
   `docs/ShoppingItemService.postman_collection.json`
4. All API routes will appear under **Shopping Item Service** collection

### âœ… Included Requests
| Service | Method | Endpoint | Description |
|----------|--------|-----------|--------------|
| **API Gateway** | `POST` | `/api/command/items` | Create item |
| **API Gateway** | `GET` | `/api/query/items` | Get all items |
| **API Gateway** | `GET` | `/api/query/items/:id` | Get item by ID |
| **API Gateway** | `PUT` | `/api/command/items/:id` | Update item |
| **API Gateway** | `DELETE` | `/api/command/items/:id` | Soft delete item |

> ğŸ’¡ *Each request automatically uses the correct `localhost` ports defined in your Docker/Local setup.*
---

---

## ğŸ§ª Manual Testing / Test Plan

After setup, you can manually verify that the system works end-to-end.  
Use Postman or any API client to test these scenarios.

| Step | Action | Expected Result |
|------|---------|-----------------|
| 1ï¸âƒ£ | **Create Item** â€“ Send a `POST` request to `/api/command/items` with name and price. | Item is saved in PostgreSQL, event appears in RabbitMQ, and item is created in MongoDB. |
| 2ï¸âƒ£ | **Get All Items** â€“ Send a `GET` request to `/api/query/items`. | Newly created item should appear in the list from MongoDB. |
| 3ï¸âƒ£ | **Get Item by ID** â€“ Send a `GET` request to `/api/query/items/:id`. | Returns the specific item details. |
| 4ï¸âƒ£ | **Update Item** â€“ Send a `PUT` request to `/api/command/items/:id` with new data. | Updated data is saved in PostgreSQL and reflected in MongoDB after event propagation. |
| 5ï¸âƒ£ | **Delete Item** â€“ Send a `DELETE` request to `/api/command/items/:id`. | Item is soft deleted in PostgreSQL and removed from MongoDB. |
| 6ï¸âƒ£ | **Verify Consistency** â€“ Check both databases. | PostgreSQL shows `deletedAt` timestamp; MongoDB no longer contains the item. |

ğŸ§  **Tip:** Always make sure your worker process is running (`npm run worker`) â€”  
otherwise, events will remain unprocessed in the Outbox.

---




